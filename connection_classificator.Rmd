---
title: "Connection Classification"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))
suppressMessages(library(ISLR))
suppressMessages(library(caret))
suppressMessages(library(doMC))
suppressMessages(library(plotly))
registerDoMC(cores=4)

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

### Getting and proccesing the data
```{r}
library(stringr)
myData = read.csv('./datasets/data_all_result.txt', stringsAsFactors = F, sep = ' ')
#Create data backup
myData.bkup <- myData
#Create new column: length of model, and number of periodicity, duration and size characteristic in the model.
myData = myData %>% mutate(letter_count = nchar(State))
#Periodicity
myData = myData %>% mutate(strong_p = str_count(State,'[a-i]'))
myData = myData %>% mutate(weak_p = str_count(State,'[A-I]'))
myData = myData %>% mutate(weak_np = str_count(State,'[r-z]'))
myData = myData %>% mutate(strong_np = str_count(State,'[R-Z]'))
#Duration
myData = myData %>% mutate(duration_s = str_count(State,'(a|A|r|R|1|d|D|u|U|4|g|G|x|X|7)'))
myData = myData %>% mutate(duration_m = str_count(State,'(b|B|s|S|2|e|E|v|V|5|h|H|y|Y|8)'))
myData = myData %>% mutate(duration_l = str_count(State,'(c|C|t|T|3|f|F|w|W|6|i|I|z|Z|9)'))
#Size
myData = myData %>% mutate(size_s = str_count(State,'[a-c]') + str_count(State,'[A-C]') + str_count(State,'[r-t]') + str_count(State,'[R-T]') + str_count(State,'[1-3]'))
myData = myData %>% mutate(size_m = str_count(State,'[d-f]') + str_count(State,'[D-F]') + str_count(State,'[u-w]') + str_count(State,'[U-W]') + str_count(State,'[4-6]'))
myData = myData %>% mutate(size_l = str_count(State,'[g-i]') + str_count(State,'[G-I]') + str_count(State,'[x-z]') + str_count(State,'[X-Z]') + str_count(State,'[7-9]'))

#Remove from LabelName unnecessary characters (ej: V42, -17)
myData <- myData %>% mutate(LabelName = gsub('V[0-9]+-','',LabelName))
myData <- myData %>% mutate(LabelName = gsub('-[0-9]+','',LabelName))
myData <- myData %>% mutate(LabelName = gsub('CC[0-9]+-','CC-',LabelName))

#Keep only connection with more than 3 symbols
myData <- myData %>% filter(letter_count > 3)

#Periodicity %
myData <- myData %>% mutate(strong_p = (strong_p / letter_count))
myData <- myData %>% mutate(weak_p = (weak_p / letter_count))
myData <- myData %>% mutate(strong_np = (strong_np / letter_count))
myData <- myData %>% mutate(weak_np = (weak_np / letter_count))
#Duration %
myData <- myData %>% mutate(duration_s = (duration_s / letter_count))
myData <- myData %>% mutate(duration_m = (duration_m / letter_count))
myData <- myData %>% mutate(duration_l = (duration_l / letter_count))
#Size %
myData <- myData %>% mutate(size_s = (size_s / letter_count))
myData <- myData %>% mutate(size_m = (size_m / letter_count))
myData <- myData %>% mutate(size_l = (size_l / letter_count))

#head(myData)
myData[1:20,]

#Making feature vectors
feature_vectors = myData[,c('strong_p','weak_p','weak_np','strong_np','duration_s','duration_m','duration_l','size_s','size_m','size_l','letter_count','Label','LabelName','port','proto')]
names(feature_vectors) = c("sp","wp","wnp","snp","ds","dm","dl","ss","sm","sl","length","class","subclass","port","proto")
feature_vectors$class = factor(feature_vectors$class)
feature_vectors$subclass = factor(feature_vectors$subclass)
feature_vectors$proto = factor(feature_vectors$proto)
```

### Create training set and testset
```{r}
set.seed(300)
trainIndex <- createDataPartition(feature_vectors$class, p=0.80, list=FALSE)
data_train <- feature_vectors[ trainIndex,]
data_test <- feature_vectors[-trainIndex,]

#data_train = data_train %>% filter(length>5)
train <- upSample(x = data_train,  y = data_train$class, yname="class")
#train <- upSample(x = train,  y = train$subclass, yname="class")
training <- train[,-c(11,12)]
testing <- data_test[,-c(11)]
training
testing
train

ctrl_fast <- trainControl(method="cv", 
                     repeats=2,
                     number=10, 
                     summaryFunction=twoClassSummary,
                     verboseIter=T,
                     classProbs=TRUE,
                     allowParallel = TRUE)  
ctrl <- trainControl(method="repeatedcv",repeats = 3) #,classProbs=TRUE,summaryFunction = twoClassSummary)
```


### Random Forest Classificator
```{r}
  # Random Forest
rfFit <- train(class ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl,
               data = training,
               metric="ROC",
               method = "rf",
               trControl = ctrl_fast)

rfFit
rfFit$finalModel
```

```{r}
predsrfprobs=predict(rfFit,testing,type='prob')
predsrf=ifelse(predsrfprobs$Botnet >=0.9,'Botnet','Normal')
confusionMatrix(predsrf,testing$class)
```

```{r}
library(ggplot2)
library(plotROC)
selectedIndices <- rfFit$pred$mtry == 2
ggplot(cbind(predsrfprobs,class=testing$class), 
       aes(m = Botnet, d = factor(class, labels=c("Normal","Botnet"),levels = c("Normal", "Botnet")))) + 
    geom_roc(hjust = -0.4, vjust = 1.5,colour='orange') + 
  theme_bw()

cbind(predsrfprobs,class=testing$class)
```


### KNN
```{r}
#Checking distibution in origanl data and partitioned data
prop.table(table(training$class)) * 100
prop.table(table(testing$class)) * 100
prop.table(table(feature_vectors$class)) * 100

trainX <- training[,names(training) != "class"]
preProcValues <- preProcess(x = trainX,method = c("center", "scale"))
preProcValues
```
```{r}
knnFit <- train(class ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl, data = training, method = "knn", trControl = ctrl_fast, preProcess = c("center","scale"), tuneLength = 20)

#Output of kNN fit
knnFit
```
```{r}
#Plotting yields Number of Neighbours Vs accuracy (based on repeated cross validation)
plot(knnFit)
```
```{r}
knnPredict <- predict(knnFit,newdata = testing )
#Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, testing$class )
```
```{r}
mean(knnPredict == testing$class)
```
```{r}
library(pROC)
knnPredict <- predict(knnFit,newdata = testing , type="prob")
knnROC <- roc(testing$class,knnPredict[,"Botnet"], levels = c('Normal','Botnet'))#rev(testing$class))
knnROC
```

```{r}
ggplot(cbind(knnPredict,class=testing$class), 
       aes(m = Botnet, d = factor(class, labels=c("Normal","Botnet"),levels = c("Normal", "Botnet")))) + 
    geom_roc(hjust = -0.4, vjust = 1.5,colour='orange') + 
  theme_bw()

#plot(knnROC, type="S", print.thres= 0.5)
```
### Logistic Regression

```{r}
logicRFit <- train(class ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl, method='glm', trControl = ctrl_fast,preProcess=c('scale', 'center'), data=training, family=binomial(link='logit'))
#logicRFit <- train(class ~ sp*wp*wnp*snp*ds*dm*dl*ss*sm*sl, method='glm', trControl = ctrl_fast,preProcess=c('scale', 'center'), data=training, family=binomial(link='logit'))
#logicRFit <- train(class ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl, method='glm', trControl = ctrl_fast,preProcess=c('scale', 'center'), data=training, family=binomial(link='logit'))

#summary(logicRFit)
#Output of Logistic Regression fit
logicRFit
```

```{r}

logicRPredict <- predict(logicRFit, newdata = testing )

confusionMatrix(logicRPredict, testing$class)
```
```{r}
logicRPredict <- predict(logicRFit, newdata = testing, type="prob")
logicROC <- roc(testing$class,logicRPredict[,"Botnet"], levels = c('Normal','Botnet'))#rev(testing$class))

ggplot(cbind(logicRPredict,class=testing$class), 
       aes(m = Botnet, d = factor(class, labels=c("Normal","Botnet"),levels = c("Normal", "Botnet")))) + 
    geom_roc(hjust = -0.4, vjust = 1.5,colour='orange') + 
  theme_bw()

#logicROC
```

### Naive Bayes
```{r}
naiveBayesFit <- train(class ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl, method='nb', trControl = ctrl_fast,preProcess=c('scale', 'center'), data=training)
naiveBayesFit
```

```{r}
naiveBayesPredict <- predict(naiveBayesFit, newdata = testing)

confusionMatrix(naiveBayesPredict, testing$class)
```
```{r}
naiveBayesPredict <- predict(naiveBayesFit, newdata = testing, type = 'prob')
naiveBayesROC <- roc(testing$class,naiveBayesPredict[,"Botnet"], levels = c('Normal','Botnet'))#rev(testing$class))
naiveBayesROC

ggplot(cbind(naiveBayesPredict,class=testing$class), 
       aes(m = Botnet, d = factor(class, labels=c("Normal","Botnet"),levels = c("Normal", "Botnet")))) + 
    geom_roc(hjust = -0.4, vjust = 1.5,colour='orange') + 
  theme_bw()

#plot(naiveBayesROC, type="S", print.thres= 0.5)
```


### Suport Vector Machine
```{r}
svmFit <- train(class ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl, method='svmLinear', trControl = ctrl_fast,preProcess=c('scale', 'center'), data=training, family=binomial(link='logit'))
svmFit
```

```{r}
svmPredict <- predict(svmFit, newdata = testing)
confusionMatrix(svmPredict, testing$class)
```

```{r}
svmPredict <- predict(svmFit, newdata = testing, type = "prob")

svmROC <- roc(testing$class,svmPredict[,"Botnet"], levels = c('Normal','Botnet'))#rev(testing$class))
svmROC

ggplot(cbind(svmPredict,class=testing$class), 
       aes(m = Botnet, d = factor(class, labels=c("Normal","Botnet"),levels = c("Normal", "Botnet")))) + 
    geom_roc(hjust = -0.4, vjust = 1.5,colour='orange') + 
  theme_bw()

```


### Comparing Models
```{r}
resamps <- resamples(list(rf = rfFit, lr = logicRFit, nv = naiveBayesFit, svm = svmFit))
summary(resamps)
bwplot(resamps)
diffs <- diff(resamps)
summary(diffs)
values=resamps$values
values
names(values)[2]<-"rfSens"

ggplot(values)+
  geom_boxplot(aes(y=rfSens,x=1))

```
### Making probabilistic table.
```{r}
# Botnet probabilistic table
botnet_prob_result = data.frame(testing$class, predsrfprobs$Botnet, knnPredict$Botnet, logicRPredict$Botnet, naiveBayesPredict$Botnet ,svmPredict$Botnet, testing$subclass, testing$port, testing$proto)
#botnet_prob_result = botnet_prob_result %>% mutate(subclass = data_test$subclass)
names(botnet_prob_result) = c('TrueClass','RamdomForest','KNN','LogisticRegression', 'NaiveBayes', 'SVM','subclass','port','proto')
botnet_prob_result
```


```{r}
#load("./botnet_prob_results.Rda")
library(grid)
library(gridExtra)
botnet_prob_result %>% group_by(subclass) %>% summarise(n=n(),sum_RF=sum(RamdomForest),sum_KNN=sum(KNN),sum_LR=sum(LogisticRegression),sum_NB=sum(NaiveBayes),sum_SVM=sum(SVM)) %>% arrange(desc(n))
botnet_prob_result %>% group_by(subclass) %>% summarise(n=n(),mean=mean(NaiveBayes),sd=sd(NaiveBayes)) %>% arrange(desc(n))%>% top_n(10)
botnet_10_top<-botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% group_by(subclass) %>% summarise(n=n()) %>% arrange(desc(n))%>% top_n(10)

botnet_10_top<-inner_join(botnet_10_top,botnet_prob_result,by="subclass")

rf_plot<-bwplot(subclass~RamdomForest,data=botnet_10_top,do.out = FALSE,scales=list(y=list(draw=FALSE)))
knn_plot<-bwplot(subclass~KNN,data=botnet_10_top,do.out = FALSE,scales=list(y=list(draw=FALSE)))
rl_plot<-bwplot(subclass~LogisticRegression,data=botnet_10_top,do.out = FALSE,scales=list(y=list(draw=FALSE)))
svm_plot<-bwplot(subclass~SVM,data=botnet_10_top,do.out = FALSE,scales=list(y=list(draw=FALSE)))

pl = list(knn_plot, rf_plot,rl_plot,svm_plot)
# do.call(grid.arrange, c(pl, nrow=1))
do.call(grid.arrange, c(lapply(pl, update), list(nrow=1)))
```

#### some heatmaps
```{r heatmaps}
library(scales)
knn_m<-matrix(botnet_prob_result[1:1830,]$KNN,ncol=30,nrow=61)
svm_m<-matrix(botnet_prob_result[1:1830,]$SVM,ncol=30,nrow=61)
lr_m<-matrix(botnet_prob_result[1:1830,]$LogisticRegression,ncol=30,nrow=61)
nb_m<-matrix(botnet_prob_result[1:1830,]$NaiveBayes,ncol=30,nrow=61)
rf_m<-matrix(botnet_prob_result[1:1830,]$RamdomForest,ncol=30,nrow=61)

mdf<-as.data.frame(knn_m)
mdf<-cbind(mdf,id=seq(1:61))
mdf<-reshape2::melt(mdf,id.vars=c("id"))
h1<-ggplot(mdf)+
  geom_tile(aes(x=id,y=variable,fill=value),
            colour = "white") +
  scale_fill_gradient(low = "white",
    high = "orange")+ylab("")+xlab("")+
  guides(fill=FALSE)


mdf<-as.data.frame(svm_m)
mdf<-cbind(mdf,id=seq(1:61))
mdf<-reshape2::melt(mdf,id.vars=c("id"))
h2<-ggplot(mdf)+
  geom_tile(aes(x=id,y=variable,fill=value),
            colour = "white") +
  scale_fill_gradient(low = "white",
    high = "orange")+ylab("")+xlab("")+
  guides(fill=FALSE)


mdf<-as.data.frame(rf_m)
mdf<-cbind(mdf,id=seq(1:61))
mdf<-reshape2::melt(mdf,id.vars=c("id"))
h3<-ggplot(mdf)+
  geom_tile(aes(x=id,y=variable,fill=value),
            colour = "white") +
  scale_fill_gradient(low = "white",
    high = "orange")+ylab("")+xlab("")+
  guides(fill=FALSE)


mdf<-as.data.frame(nb_m)
mdf<-cbind(mdf,id=seq(1:61))
mdf<-reshape2::melt(mdf,id.vars=c("id"))
h4<-ggplot(mdf)+
  geom_tile(aes(x=id,y=variable,fill=value),
            colour = "white") +
  scale_fill_gradient(low = "white",
    high = "orange")+ylab("")+xlab("")+
  guides(fill=FALSE)
grid.arrange(h1,h2,h3,h4,ncol=2,nrow=2)
```

#### difference heatmaps
```{r heatmap diff}
mdf<-as.data.frame(rf_m - knn_m)
mdf<-cbind(mdf,id=seq(1:61))
mdf<-reshape2::melt(mdf,id.vars=c("id"))
mdf<-cbind(mdf,subclass=(botnet_prob_result[1:1830,]$subclass))

diff<-ggplot(mdf)+
  geom_tile(aes(x=id,y=variable,fill=value,text=subclass),
            colour = "white") +
  scale_fill_gradientn(colours=c("red","white","green"),
           values  = rescale(c(min(mdf$value), 0.05, max(mdf$value))))+
           guides(fill=FALSE)+theme_bw()  
ggplotly(diff)
d3heatmap(rf_m - knn_m,colors = "Blues",cellnote=matrix(botnet_prob_result[1:1830,]$subclass,ncol=30,nrow=61))
```

### Subclass probability analisys (Attempt I)
KNN vs RF.
```{r}
a=mdf %>% filter(value< -0.09) %>% group_by(subclass) %>% summarise(totless009=n()) %>% arrange(desc(totless009))
b=mdf  %>% group_by(subclass) %>% summarise(total=n()) %>% arrange(desc(total))

subclass_percent_diff<-inner_join(a,b,by="subclass") %>% mutate(percent=totless009/total) %>% arrange(desc(total)) 
subclass_percent_diff

subclass_detections<-botnet_prob_result %>% mutate(detected_rf=ifelse(RamdomForest>0.5,"Botnet","Normal"),
                              detected_knn=ifelse(KNN>0.5,"Botnet","Normal")) %>% 
                              mutate(correct_rf=ifelse(detected_rf==TrueClass,1,0))%>%
                              mutate(correct_knn=ifelse(detected_knn==TrueClass,1,0)) %>% 
  group_by(subclass) %>% summarise(total_correct_rf=sum(correct_rf),total_correct_knn=sum(correct_knn))


inner_join(subclass_detections,subclass_percent_diff,by="subclass")

mdf<-cbind(mdf,rf=botnet_prob_result$RamdomForest[1:1830],knn=botnet_prob_result$KNN[1:1830],trueclass=botnet_prob_result$TrueClass[1:1830])
botnet_prob_result
mdf %>% filter(value< -0.09) %>% filter(trueclass=="Botnet")
mdf %>% filter(value> 0.09) %>% filter(trueclass=="Normal")


```
### Useful functions
```{r}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```


### Subclass probability analisys (Attempt II)
Random Forest vs. world
```{r}
botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% group_by(subclass) %>% summarise(n=n(),sum_RF=sum(RamdomForest),sum_KNN=sum(KNN),sum_LR=sum(LogisticRegression),sum_NB=sum(NaiveBayes),sum_SVM=sum(SVM)) %>% arrange(desc(n))

subclass = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% group_by(subclass) %>% summarise(n = n()) %>% arrange(desc(n))
sc1 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < KNN) %>% group_by(subclass) %>% summarise(best_knn = n())
sc2 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < LogisticRegression) %>% group_by(subclass) %>% summarise(best_lr = n())
sc3 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < NaiveBayes) %>% group_by(subclass) %>% summarise(best_nb = n())
sc4 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < SVM) %>% group_by(subclass) %>% summarise(best_svm = n())
botnet_prob_result_table_subclass = inner_join(subclass,sc1,by="subclass") %>% inner_join(sc2,by="subclass") %>% inner_join(sc3,by="subclass") %>% inner_join(sc4,by="subclass")
botnet_prob_result_table_subclass

ports = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% group_by(port) %>% summarise(n = n()) %>% arrange(desc(n))
p1 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < KNN) %>% group_by(port) %>% summarise(best_knn = n())
p2 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < LogisticRegression) %>% group_by(port) %>% summarise(best_lr = n())
p3 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < NaiveBayes) %>% group_by(port) %>% summarise(best_nb = n())
p4 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < SVM) %>% group_by(port) %>% summarise(best_svm = n())
botnet_prob_result_table_port = inner_join(ports,p1,by="port") %>% inner_join(p2,by="port") %>% inner_join(p3,by="port") %>% inner_join(p4,by="port")
botnet_prob_result_table_port

protos = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% group_by(proto) %>% summarise(n = n()) %>% arrange(desc(n))
pr1 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < KNN) %>% group_by(proto) %>% summarise(best_knn = n())
pr2 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < LogisticRegression) %>% group_by(proto) %>% summarise(best_lr = n())
pr3 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < NaiveBayes) %>% group_by(proto) %>% summarise(best_nb = n())
pr4 = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < SVM) %>% group_by(proto) %>% summarise(best_svm = n())
botnet_prob_result_table_proto = inner_join(protos,pr1,by="proto") %>% inner_join(pr2,by="proto") %>% inner_join(pr3,by="proto") %>% inner_join(pr4,by="proto")
botnet_prob_result_table_proto

############################### Filter by epsilon distance ########################################
epsilon = 0.09
sc1_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < KNN) %>% filter((KNN - RamdomForest) > epsilon) %>% group_by(subclass) %>% summarise(best_knn = n())
sc2_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < LogisticRegression) %>% filter((LogisticRegression - RamdomForest) > epsilon) %>% group_by(subclass) %>% summarise(best_lr = n())
sc3_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < NaiveBayes) %>% filter((NaiveBayes - RamdomForest) > epsilon) %>% group_by(subclass) %>% summarise(best_nb = n())
sc4_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < SVM) %>% filter((SVM - RamdomForest) > epsilon) %>% group_by(subclass) %>% summarise(best_svm = n())
botnet_prob_result_table_subclass_e = inner_join(subclass,sc1_e,by="subclass") %>% inner_join(sc2_e,by="subclass") %>% inner_join(sc3_e,by="subclass") %>% inner_join(sc4_e,by="subclass")
botnet_prob_result_table_subclass_e

p1_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < KNN) %>% filter((KNN - RamdomForest) > epsilon) %>% group_by(port) %>% summarise(best_knn = n())
p2_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < LogisticRegression) %>% filter((LogisticRegression - RamdomForest) > epsilon) %>% group_by(port) %>% summarise(best_lr = n())
p3_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < NaiveBayes) %>% filter((NaiveBayes - RamdomForest) > epsilon) %>% group_by(port) %>% summarise(best_nb = n())
p4_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < SVM) %>% filter((SVM - RamdomForest) > epsilon) %>% group_by(port) %>% summarise(best_svm = n())
botnet_prob_result_table_port_e = inner_join(ports,p1_e,by="port") %>% inner_join(p2_e,by="port") %>% inner_join(p3_e,by="port") %>% inner_join(p4_e,by="port")
botnet_prob_result_table_port_e

pr1_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < KNN) %>% filter((KNN - RamdomForest) > epsilon) %>% group_by(proto) %>% summarise(best_knn = n())
pr2_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < LogisticRegression) %>% filter((LogisticRegression - RamdomForest) > epsilon) %>% group_by(proto) %>% summarise(best_lr = n())
pr3_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < NaiveBayes) %>% filter((NaiveBayes - RamdomForest) > epsilon) %>% group_by(proto) %>% summarise(best_nb = n())
pr4_e = botnet_prob_result %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < SVM) %>% filter((SVM - RamdomForest) > epsilon) %>% group_by(proto) %>% summarise(best_svm = n())
botnet_prob_result_table_proto_e = inner_join(protos,pr1_e,by="proto") %>% inner_join(pr2_e,by="proto") %>% inner_join(pr3_e,by="proto") %>% inner_join(pr4_e,by="proto")
botnet_prob_result_table_proto_e

botnet_prob_result_table_subclass_e$subclass = as.factor(botnet_prob_result_table_subclass_e$subclass)
data <- cbind(botnet_prob_result_table_subclass_e,id=seq(1:nrow(botnet_prob_result_table_subclass_e)))
data <- reshape2::melt(data[,-1],id.vars=c("id"))
data <- cbind(sub_class = botnet_prob_result_table_subclass_e$subclass,data)
p1 <- ggplot(data, aes(sub_class, value)) +
  geom_bar(aes(fill = variable), position = "dodge", stat="identity")

botnet_prob_result_table_port_e$port = as.factor(botnet_prob_result_table_port_e$port)
data <- cbind(botnet_prob_result_table_port_e,id=seq(1:nrow(botnet_prob_result_table_port_e)))
data <- reshape2::melt(data[,-1],id.vars=c("id"))
data <- cbind(ports = botnet_prob_result_table_port_e$port,data)
p2 <- ggplot(data, aes(ports, value)) +
  geom_bar(aes(fill = variable), position = "dodge", stat="identity")

botnet_prob_result_table_proto_e$proto = as.factor(botnet_prob_result_table_proto_e$proto)
data <- cbind(botnet_prob_result_table_proto_e,id=seq(1:nrow(botnet_prob_result_table_proto_e)))
data<-reshape2::melt(data[,-1],id.vars=c("id"))
data = cbind(protos = botnet_prob_result_table_proto_e$proto,data)
p3 <- ggplot(data, aes(protos, value)) +
  geom_bar(aes(fill = variable), position = "dodge", stat="identity")
multiplot(p1, p2, p3,cols=3)
```


### Clustering and PCA
```{r clustering}

kmeans_mod<-kmeans(testing[,1:10],centers = 10)
testing_cluster<-cbind(testing,cluster=kmeans_mod$cluster)
pca<-prcomp(testing[,c(-11,-12,-13,-14)], center = TRUE, scale. = TRUE) 
pca_testing<-data.frame(pca$x,class=testing_cluster$class,
                              subclass=testing_cluster$subclass,
                               cluster=testing_cluster$cluster
                               )
g<-ggplot(pca_testing,aes(x=PC1,y=PC2))+
  geom_jitter(aes(color=as.factor(subclass),text=cluster,shape=class))+
  #geom_point(aes(shape=asignacion),size=3)+
  ylab("PC1")+xlab("PC2")+
  theme_classic()+
#scale_shape_manual(values=c(8,6))+
   guides(color=FALSE,alpha=FALSE)
ggplotly(g)

```
###### Cluster probability analisys (Attempt II)
```{r}
botnet_prob_cluster <- cbind(botnet_prob_result,cluster=kmeans_mod$cluster)
botnet_prob_cluster
epsilon = 0.09
cluster = botnet_prob_cluster %>% filter(TrueClass == 'Botnet') %>% group_by(cluster) %>% summarise(n = n()) %>% arrange(desc(n))
cl1 = botnet_prob_cluster %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < KNN) %>% group_by(cluster) %>% summarise(best_knn = n())
cl2 = botnet_prob_cluster %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < LogisticRegression) %>% group_by(cluster) %>% summarise(best_lr = n())
cl3 = botnet_prob_cluster %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < NaiveBayes) %>% group_by(cluster) %>% summarise(best_nb = n())
cl4 = botnet_prob_cluster %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < SVM) %>% group_by(cluster) %>% summarise(best_svm = n())
botnet_prob_result_table_cluster = inner_join(cluster,cl1,by="cluster") %>% inner_join(cl2,by="cluster") %>% inner_join(cl3,by="cluster") %>% inner_join(cl4,by="cluster")
botnet_prob_result_table_cluster

cl1_e = botnet_prob_cluster %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < KNN) %>% filter((KNN - RamdomForest) > epsilon) %>% group_by(cluster) %>% summarise(best_knn = n())
cl2_e = botnet_prob_cluster %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < LogisticRegression) %>% filter((LogisticRegression - RamdomForest) > epsilon) %>% group_by(cluster) %>% summarise(best_lr = n())
cl3_e = botnet_prob_cluster %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < NaiveBayes) %>% filter((NaiveBayes - RamdomForest) > epsilon) %>% group_by(cluster) %>% summarise(best_nb = n())
cl4_e = botnet_prob_cluster %>% filter(TrueClass == 'Botnet') %>% filter(RamdomForest < SVM) %>% filter((SVM - RamdomForest) > epsilon) %>% group_by(cluster) %>% summarise(best_svm = n())
botnet_prob_result_table_cluster_e = inner_join(cluster,cl1_e,by="cluster") %>% inner_join(cl2_e,by="cluster") %>% inner_join(cl3_e,by="cluster") %>% inner_join(cl4_e,by="cluster")
botnet_prob_result_table_cluster_e

cluster_bot = botnet_prob_cluster %>% filter(TrueClass == 'Botnet')

```
### 
```{r}
#library(ggalt)
library(ggfortify)
#theme_set(theme_classic())

cluster1 <- pca_testing[pca_testing$cluster == 1,]
cluster2 <- pca_testing[pca_testing$cluster == 2,]
cluster3 <- pca_testing[pca_testing$cluster == 3,]
cluster4 <- pca_testing[pca_testing$cluster == 4,]
cluster5 <- pca_testing[pca_testing$cluster == 5,]
cluster6 <- pca_testing[pca_testing$cluster == 6,]
cluster7 <- pca_testing[pca_testing$cluster == 7,]
cluster8 <- pca_testing[pca_testing$cluster == 8,]
cluster9 <- pca_testing[pca_testing$cluster == 9,]
cluster10 <- pca_testing[pca_testing$cluster == 10,]

pca_testing_botnet = pca_testing %>% filter(class == 'Botnet')
g2<-ggplot(pca_testing_botnet,aes(x=PC1,y=PC2))+
  geom_jitter(aes(color=as.factor(cluster),text=cluster,shape=as.factor(subclass)))+
  #geom_point(aes(shape=asignacion),size=3)+
  ylab("PC1")+xlab("PC2")+
  theme_classic()+
#scale_shape_manual(values=c(8,6))+
   guides(color=FALSE,alpha=FALSE)+
  geom_encircle(data = cluster1, aes(x=PC1, y=PC2)) +
  geom_encircle(data = cluster2, aes(x=PC1, y=PC2)) + 
  geom_encircle(data = cluster3, aes(x=PC1, y=PC2)) +
  geom_encircle(data = cluster4, aes(x=PC1, y=PC2)) +
  geom_encircle(data = cluster5, aes(x=PC1, y=PC2)) + 
  geom_encircle(data = cluster6, aes(x=PC1, y=PC2)) +
  geom_encircle(data = cluster7, aes(x=PC1, y=PC2)) +
  geom_encircle(data = cluster8, aes(x=PC1, y=PC2)) + 
  geom_encircle(data = cluster9, aes(x=PC1, y=PC2)) + 
  geom_encircle(data = cluster10, aes(x=PC1, y=PC2))
ggplotly(g2)

g2<-ggplot(pca_testing_botnet,aes(x=PC1,y=PC2))+
  geom_jitter(aes(color=as.factor(cluster),text=cluster,shape=as.factor(subclass)))+
  #geom_point(aes(shape=asignacion),size=3)+
  ylab("PC1")+xlab("PC2")+
  theme_classic()+
#scale_shape_manual(values=c(8,6))+
   guides(color=FALSE,alpha=FALSE)


# devtools::install_github("hrbrmstr/ggalt")

# Data frame of principal components ----------------------
df_pc <- data.frame(pca_mod$x, Species=iris$Species)  # dataframe of principal components
df_pc_vir <- df_pc[df_pc$Species == "virginica", ]  # df for 'virginica'
df_pc_set <- df_pc[df_pc$Species == "setosa", ]  # df for 'setosa'
df_pc_ver <- df_pc[df_pc$Species == "versicolor", ]  # df for 'versicolor'
 
# Plot ----------------------------------------------------
ggplot(df_pc, aes(PC1, PC2, col=Species)) + 
  geom_point(aes(shape=Species), size=2) +   # draw points
  labs(title="Iris Clustering", 
       subtitle="With principal components PC1 and PC2 as X and Y axis",
       caption="Source: Iris") + 
  coord_cartesian(xlim = 1.2 * c(min(df_pc$PC1), max(df_pc$PC1)), 
                  ylim = 1.2 * c(min(df_pc$PC2), max(df_pc$PC2))) +   # change axis limits
  geom_encircle(data = df_pc_vir, aes(x=PC1, y=PC2)) +   # draw circles
  geom_encircle(data = df_pc_set, aes(x=PC1, y=PC2)) + 
  geom_encircle(data = df_pc_ver, aes(x=PC1, y=PC2))
```


```{r}
#Normal probabilistic table
normal_prob_result = data.frame(testing$class, predsrfprobs$Normal, knnPredict$Normal, logicRPredict$Normal, naiveBayesPredict$Normal ,svmPredict$Normal)
names(normal_prob_result) = c('True Class','Ramdom Forest','KNN','Logistic Regression', 'Naive Bayes', 'Suport VM')
normal_prob_result
```

