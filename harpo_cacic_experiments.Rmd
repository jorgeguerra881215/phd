---
title: "R Notebook"
output: html_notebook
---

### Library Environment
```{r}
suppressMessages(library(tidyverse))
suppressMessages(library(stringr))
suppressMessages(library(caret))
suppressMessages(library(doMC))
suppressMessages(library(plotly))
suppressMessages(library(stringr))
registerDoMC(cores=4)
```

### Load and processing data ctu13 cleaned
```{r}
#myData_cleaned <- read.csv('/home/harpo/Dropbox/ongoing-work/git-repos/labeling-datasets/phd/datasets/ctu13.labeled.cleaned', stringsAsFactors = F, sep = '|')
myData_cleaned <- read.csv('/home/jguerra/datasets/ctu13.labeled.cleaned', stringsAsFactors = F, sep = '|')
myData_cleaned.bkp = myData_cleaned
myData_cleaned

#Periodicity
myData_cleaned = myData_cleaned %>% mutate(strong_p = str_count(State,'[a-i]'))
myData_cleaned = myData_cleaned %>% mutate(weak_p = str_count(State,'[A-I]'))
myData_cleaned = myData_cleaned %>% mutate(weak_np = str_count(State,'[r-z]'))
myData_cleaned = myData_cleaned %>% mutate(strong_np = str_count(State,'[R-Z]'))
#Duration
myData_cleaned = myData_cleaned %>% mutate(duration_s = str_count(State,'(a|A|r|R|1|d|D|u|U|4|g|G|x|X|7)'))
myData_cleaned = myData_cleaned %>% mutate(duration_m = str_count(State,'(b|B|s|S|2|e|E|v|V|5|h|H|y|Y|8)'))
myData_cleaned = myData_cleaned %>% mutate(duration_l = str_count(State,'(c|C|t|T|3|f|F|w|W|6|i|I|z|Z|9)'))
#Size
myData_cleaned = myData_cleaned %>% mutate(size_s = str_count(State,'[a-c]') + str_count(State,'[A-C]') + str_count(State,'[r-t]') + str_count(State,'[R-T]') + str_count(State,'[1-3]'))
myData_cleaned = myData_cleaned %>% mutate(size_m = str_count(State,'[d-f]') + str_count(State,'[D-F]') + str_count(State,'[u-w]') + str_count(State,'[U-W]') + str_count(State,'[4-6]'))
myData_cleaned = myData_cleaned %>% mutate(size_l = str_count(State,'[g-i]') + str_count(State,'[G-I]') + str_count(State,'[x-z]') + str_count(State,'[X-Z]') + str_count(State,'[7-9]'))

#Periodicity %
myData_cleaned <- myData_cleaned %>% mutate(strong_p = (strong_p / modelsize))
myData_cleaned <- myData_cleaned %>% mutate(weak_p = (weak_p / modelsize))
myData_cleaned <- myData_cleaned %>% mutate(strong_np = (strong_np / modelsize))
myData_cleaned <- myData_cleaned %>% mutate(weak_np = (weak_np / modelsize))
#Duration %
myData_cleaned <- myData_cleaned %>% mutate(duration_s = (duration_s / modelsize))
myData_cleaned <- myData_cleaned %>% mutate(duration_m = (duration_m / modelsize))
myData_cleaned <- myData_cleaned %>% mutate(duration_l = (duration_l / modelsize))
#Size %
myData_cleaned <- myData_cleaned %>% mutate(size_s = (size_s / modelsize))
myData_cleaned <- myData_cleaned %>% mutate(size_m = (size_m / modelsize))
myData_cleaned <- myData_cleaned %>% mutate(size_l = (size_l / modelsize))

#Making feature vectors
feature_vectors_cleaned = myData_cleaned[,c('strong_p','weak_p','weak_np','strong_np','duration_s','duration_m','duration_l','size_s','size_m','size_l','modelsize','label','class','port','proto')]
names(feature_vectors_cleaned) = c("sp","wp","wnp","snp","ds","dm","dl","ss","sm","sl","modelsize","class","subclass","port","proto")
feature_vectors_cleaned$class = factor(feature_vectors_cleaned$class)
feature_vectors_cleaned$subclass = factor(feature_vectors_cleaned$subclass)
feature_vectors_cleaned$proto = factor(feature_vectors_cleaned$proto)

feature_vectors_cleaned
myData_cleaned.bkp
myData_cleaned.bkp %>% filter(class == 'normal') %>% group_by(capture) %>% summarise(n=n())
```

### Removing excesive Botnet and Normal class (NOT  USED)
```{r, eval=FALSE, include=FALSE}
feature_vectors_cleaned.bkp <- feature_vectors_cleaned
feature_vectors_cleaned %>% group_by(class) %>% summarise(n=n()) %>% arrange(desc(n))
feature_vectors_cleaned_aux_botnet <- feature_vectors_cleaned %>% filter(class == 'Botnet-TCP-SMTP-Attempt-SPAM')
feature_vectors_cleaned_aux_normal <- feature_vectors_cleaned %>% filter(class == 'Normal-TCP-HTTP')
feature_vectors_cleaned_aux_botnet
feature_vectors_cleaned_aux_normal

feature_vectors_cleaned_aux_rest <- feature_vectors_cleaned %>% filter(class != 'Botnet-TCP-SMTP-Attempt-SPAM') %>% filter(class != 'Normal-TCP-HTTP')
feature_vectors_cleaned_aux_rest %>% group_by(class) %>% summarise(n=n()) %>% arrange(desc(n))
aux1 <- rbind(feature_vectors_cleaned_aux_botnet[1:500,],feature_vectors_cleaned_aux_normal[1:500,])
aux1 %>% group_by(class) %>% summarise(n=n()) %>% arrange(desc(n))
aux <- rbind(feature_vectors_cleaned_aux_rest,aux1)
aux %>% group_by(class) %>% summarise(n=n()) %>% arrange(desc(n))
feature_vectors_cleaned <- aux %>% filter(proto=='udp' |proto=='tcp')
feature_vectors_cleaned
nrow(feature_vectors_cleaned)
```


### Training configuration
```{r}
ctrl_fast <- trainControl(method="cv", 
                     repeats=1,
                     number=5, 
                     summaryFunction=twoClassSummary,
                     verboseIter=T,
                     classProbs=TRUE,
                     allowParallel = TRUE)  
```

### Experiment 1: An RF iteration with incremental (in 200) training set and tested with the rest.

```{r}
step_size=200
ncluster=7

set.seed(201)
size_features_vector <- nrow(feature_vectors_cleaned)
feature_vectors_cleaned$id<-seq(1,size_features_vector) #adding ID

vector_sampled <- feature_vectors_cleaned[sample(size_features_vector, size_features_vector), ] #shuffle
vector_sampled<-vector_sampled[-which(is.na(vector_sampled$port)),] # removing  NA values from port 

aux_vector_sampled<-vector_sampled %>% select(-id,-modelsize,-class,-subclass,-proto) # removing non-required features
clusters <- kmeans(aux_vector_sampled,ncluster,nstart = 1) #removing NAs
vector_sampled <- cbind(vector_sampled, clusterid = clusters$cluster) #Adding clusterid
    
split_size_training = size_features_vector / step_size
i=1
results<-c()
#vector_sampled
for (i in 1:split_size_training){
  trainset<-vector_sampled[1:(i*step_size),]
  testset<-vector_sampled[((i*step_size)+1):nrow(vector_sampled),]
  new_rfFit <- train(subclass ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl+clusterid+proto, #clusterid+proto
                 data = trainset,
                 metric="ROC",
                 method = "rf",
                 trControl = ctrl_fast)
  #Testing predict
  predsrfprobs <- predict(new_rfFit,testset,type='prob')
  results<-rbind(results,cbind(id=testset$id,size=i*step_size,prediction=predsrfprobs$botnet))  
  
}

results
f1_vector<-c()
for (i in 1:split_size_training){
  size_value=i*step_size
  ids<-(as.data.frame(results)%>% filter(size==size_value))$id
  classes<-vector_sampled[match(ids,vector_sampled$id),]$subclass
  
  results_extended<-cbind((as.data.frame(results)%>% filter(size==size_value)),class=classes) %>%     mutate(class_predicted=ifelse(prediction>0.5,"botnet","normal"))

  cm<-confusionMatrix(results_extended$class,results_extended$class_predicted,mode = 'everything')
  f1_vector<-c(f1_vector,cm$byClass['F1'])
}

data<-as.data.frame(cbind(x=seq(1,length(f1_vector)),cluster=f1_vector))
ggplot(data)+
  geom_line(aes(x=x,y=cluster),color='red') + 
  labs(title="Random Forest performance with incremental training data", 
       #subtitle="Drawn from Long Data format", 
       caption="Source: CTU-13", 
       x = "Iterations",
       y="F1 Score", 
       color=NULL)

f1_vector
```
### plot graphic bar filtered by connection port and training set size(200, 4000, 8000)
```{r}
#c(200,2000,4000,7000)
a <- results
b <- as.data.frame(results)
#b
result_200 <- b %>% filter(size == 8000)
result_200 <- result_200 %>% arrange(id)
#result_200
feature_vectors_cleaned_predicted <- feature_vectors_cleaned %>% filter(id %in% result_200$id)
feature_vectors_cleaned_predicted <- cbind(feature_vectors_cleaned_predicted,result_200[,3])
feature_vectors_cleaned_predicted_aux <- feature_vectors_cleaned_predicted[,-c(1:12,15)]
names(feature_vectors_cleaned_predicted_aux) <- c("subclass","port","id","predict")
more_representative_ports <- c(25,53,80,123,443,6667) #<- feature_vectors_cleaned_predicted_aux %>% group_by(port) %>% summarise(n=n()) %>% arrange(desc(n)) %>% filter(n > 50)
#more_representative_ports
feature_vectors_cleaned_predicted_aux <- feature_vectors_cleaned_predicted_aux %>% filter(port %in% more_representative_ports)
feature_vectors_cleaned_predicted_aux$port <- as.factor(feature_vectors_cleaned_predicted_aux$port)
feature_vectors_cleaned_predicted_aux.normal <- feature_vectors_cleaned_predicted_aux %>% filter(subclass == 'normal')
feature_vectors_cleaned_predicted_aux.botnet <- feature_vectors_cleaned_predicted_aux %>% filter(subclass == 'botnet')
feature_vectors_cleaned_predicted_aux.normal <- feature_vectors_cleaned_predicted_aux.normal %>% mutate(prediction = ifelse(subclass == 'normal' & predict < 0.5,'correct','incorrect'))
feature_vectors_cleaned_predicted_aux.botnet <- feature_vectors_cleaned_predicted_aux.botnet %>% mutate(prediction = ifelse(subclass == 'botnet' & predict > 0.5,'correct','incorrect'))
feature_vectors_cleaned_predicted_aux.normal$predict <- as.factor(feature_vectors_cleaned_predicted_aux.normal$predict)
feature_vectors_cleaned_predicted_aux.botnet$predict <- as.factor(feature_vectors_cleaned_predicted_aux.botnet$predict)

#feature_vectors_cleaned_predicted_aux.normal

ggplot(feature_vectors_cleaned_predicted_aux.botnet) +
  geom_bar(aes(x=port,fill=prediction), position = "dodge") +
  labs(title="Good and bag predictions by port for botnet connection", 
       caption="Source: CTU-13", 
       x = "class",
       y="Count", 
       color=NULL) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

ggplot(feature_vectors_cleaned_predicted_aux.normal) +
  geom_bar(aes(x=port,fill=prediction), position = "dodge") +
  labs(title="Good and bag predictions by port for normal connection", 
       caption="Source: CTU-13", 
       x = "class",
       y="Count", 
       color=NULL) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
  

ggplot(rbind(feature_vectors_cleaned_predicted_aux.normal,feature_vectors_cleaned_predicted_aux.botnet) ) +
  geom_bar(aes(x=port,fill=prediction)) +
  labs(title="", 
       caption="Source: CTU-13",
       x = "port",
       y="number of connections", 
       color=NULL) + 
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.text=element_text(size=12),
        legend.justification=c(1,1),legend.position=c(1,1),legend.title=element_blank()) + 
  scale_fill_manual("legend", values = c("correct" = "#00bfc4ff", "incorrect" = "#f8766dff")) + 
  theme_bw() 


```

```{r}
f1_vector
vector_sampled
vector_sampled_aux <- vector_sampled
vector_sampled_aux$port <- as.factor(vector_sampled_aux$port)
ggplot(data = vector_sampled_aux[1:200,]) + 
  geom_bar(aes(subclass)) + 
  labs(title="Class distribution in first trainnig set",
       caption="Source: CTU-13", 
       x = "class",
       y="Count", 
       color=NULL)

ggplot(data = vector_sampled_aux[1:200,]) + 
  geom_bar(aes(port,fill = subclass), position = "dodge") + 
  labs(title="Class distribution in first trainnig set",
       caption="Source: CTU-13", 
       x = "class",
       y="Count", 
       color=NULL) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

ggplot(data = vector_sampled_aux) + 
  geom_bar(aes(port,fill = subclass), position = "dodge") + 
  labs(title="Class distribution in first trainnig set", 
       caption="Source: CTU-13", 
       x = "class",
       y="Count", 
       color=NULL) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


### Useful function
```{r}
# RF iteration with incremental (in 200) training set and tested with the rest. 
my_function <- function(feature_vectors_cleaned, vector_sampled, ctrl_fast){
  step_size=200
  ncluster=7
  
  #set.seed(201)
  size_features_vector <- nrow(feature_vectors_cleaned)
  feature_vectors_cleaned$id<-seq(1,size_features_vector) #adding ID
  
  #vector_sampled <- feature_vectors_cleaned[sample(size_features_vector, size_features_vector), ] #shuffle
  vector_sampled<-vector_sampled[-which(is.na(vector_sampled$port)),] # removing  NA values from port 
  
  aux_vector_sampled<-vector_sampled %>% select(-id,-modelsize,-class,-subclass,-proto) # removing non-required features
  clusters <- kmeans(aux_vector_sampled,ncluster,nstart = 1) #removing NAs
  vector_sampled <- cbind(vector_sampled, clusterid = clusters$cluster) #Adding clusterid
      
  split_size_training = size_features_vector / step_size
  i=1
  results<-c()
  #vector_sampled
  for (i in 1:split_size_training){
    trainset<-vector_sampled[1:(i*step_size),]
    testset<-vector_sampled[((i*step_size)+1):nrow(vector_sampled),]
    new_rfFit <- train(subclass ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl+clusterid+proto, #clusterid+proto
                   data = trainset,
                   metric="ROC",
                   method = "rf",
                   trControl = ctrl_fast)
    #Testing predict
    predsrfprobs <- predict(new_rfFit,testset,type='prob')
    results<-rbind(results,cbind(id=testset$id,size=i*step_size,prediction=predsrfprobs$botnet))  
    
  }
  
  results
  f1_vector<-c()
  for (i in 1:split_size_training){
    size_value=i*step_size
    ids<-(as.data.frame(results)%>% filter(size==size_value))$id
    classes<-vector_sampled[match(ids,vector_sampled$id),]$subclass
    
    results_extended<-cbind((as.data.frame(results)%>% filter(size==size_value)),class=classes) %>%     mutate(class_predicted=ifelse(prediction>0.5,"botnet","normal"))
  
    cm<-confusionMatrix(results_extended$class,results_extended$class_predicted,mode = 'everything')
    f1_vector<-c(f1_vector,cm$byClass['F1'])
  }

  f1_vector
}

# RF iteration with incremental (in 200) training set and fixed test set.
my_function_2 <- function(vector_sampled_2,vector_test, ctrl_fast){
  library(doParallel)
  cl <- makeCluster(2)
  registerDoParallel(cl)
  
  step_size=200
  split_size_training = nrow(vector_sampled_2) / step_size
  i=1
  results<-c()
  #vector_sampled
  predict_result <- foreach(i=1:split_size_training) %dopar% {
    library(caret)
    trainset <- vector_sampled_2[1:(i*step_size),]
    testset <- vector_test#vector_sampled[((i*step_size)+1):nrow(vector_sampled),]
    new_rfFit <- train(subclass ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl+clusterid+proto, #clusterid+proto
                   data = trainset,
                   metric="ROC",
                   method = "rf",
                   trControl = ctrl_fast)
    #Testing predict
    predsrfprobs <- predict(new_rfFit,testset,type='prob')
    #results<-rbind(results,cbind(id=testset$id,size=i*step_size,prediction=predsrfprobs$botnet))
    predsrfprobs$botnet
  }
  
  dd  <-  as.data.frame(matrix(unlist(predict_result), nrow=length(unlist(predict_result[1]))))
  function_result <- rowMeans(dd)
  function_result
}

# Function to plot graphs in only one graph.
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

### new exp 1: Execute 30 iterations of my_function

```{r}
step_size=200
size_features_vector <- nrow(feature_vectors_cleaned)
split_size_training = size_features_vector / step_size
result_data <- data.frame(c(1:split_size_training))
for(i in c(1:30)){
  current_seed <- 600 + i
  set.seed(current_seed)
  vector_sampled <- feature_vectors_cleaned[sample(size_features_vector, size_features_vector), ] #shuffle
  result <- my_function(feature_vectors_cleaned,vector_sampled, ctrl_fast)
  
  result_data <- cbind(result_data,result)
}

result_data
```

### new exp 2: Execute 30 iterations of my_function_2

```{r}
step_size=200
set.seed(2000)
indices <- createDataPartition(feature_vectors_cleaned$subclass, p=0.60, list=FALSE)
data_train <- feature_vectors_cleaned[ indices,]
data_test <- feature_vectors_cleaned[-indices,]

ncluster=7
data_test<-data_test[-which(is.na(data_test$port)),] # removing  NA values from port 
aux_data_test<-data_test %>% select(-modelsize,-class,-subclass,-proto) # removing non-required features
clusters_test <- kmeans(aux_data_test,ncluster,nstart = 1) #removing NAs
data_test <- cbind(data_test, clusterid = clusters_test$cluster) #Adding clusterid

size_features_vector <- nrow(data_train)
split_size_training = size_features_vector / step_size
result_data_2 <- data.frame(c(1:nrow(data_test)))
#data_train
for(i in c(1:30)){
  current_seed <- 700 + i
  set.seed(current_seed)
  vector_sampled <- data_train[sample(size_features_vector, size_features_vector), ] #shuffle
  
  vector_sampled<-vector_sampled[-which(is.na(vector_sampled$port)),] # removing  NA values from port 
  aux_vector_sampled<-vector_sampled %>% select(-modelsize,-class,-subclass,-proto) # removing non-required features
  clusters <- kmeans(aux_vector_sampled,ncluster,nstart = 1) #removing NAs
  vector_sampled_2 <- cbind(vector_sampled, clusterid = clusters$cluster) #Adding clusterid
  
  result_2 <- my_function_2(vector_sampled_2,data_test, ctrl_fast)
  
  result_data_2 <- cbind(result_data_2,result_2)
}

result_data_2

#result_2 <- my_function_2(vector_sampled,data_test, ctrl_fast)
#result_2
```

### Plot result of exp1
```{r}
result_data.bkp <- result_data
result_data
data_means <- rowMeans(result_data[,c(-1)])
data_means
result_data_2 <- result_data[,-1]
data_sd <- transform(result_data_2, SD=apply(result_data_2,1, sd, na.rm = TRUE))
data_sd[,'SD']

size_features_vector <- nrow(feature_vectors_cleaned)
split_size_training = size_features_vector / step_size
values<-c()
#vector_sampled
for (i in 1:44){
    values[i] = i*step_size
}
values
aux_data <- cbind(ds=data_sd[,'SD'],m=data_means)
aux_data
data<-as.data.frame(cbind(x=values,cluster=aux_data))
data[,'m'] - (data[,'ds'] / 2)
names(data) <- c("x","ds","m")
data
pd <- position_dodge(0.5)
ggplot(data, aes(x=x,y=m))+
  #geom_errorbar(aes(ymin=m-(ds/2), ymax=m+(ds/2)), colour="black", width=0.2) +
  geom_line(color='red') + 
  geom_point(color = 'red') +
  geom_errorbar(aes(ymin=m-(ds/2), ymax=m+(ds/2)), colour="black", width=0.2) +
  labs(
       #title="Random Forest performance with incremental training data", 
       #subtitle="Drawn from Long Data format", 
       caption="Source: CTU-13", 
       x = "training-set size",
       y="F1 Score", 
       color=NULL) +
  theme_bw() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

result_data.bkp

#write.table(result_data.bkp,file="result_data_cacic.txt",sep="|", row.names = F)
```


### new experiment 2: Rf with 200, 2000, 4000 and 8000 connections in training set.
```{r}
step_size=200
ncluster=7

set.seed(201)
size_features_vector <- nrow(feature_vectors_cleaned)
feature_vectors_cleaned$id<-seq(1,size_features_vector) #adding ID

vector_sampled <- feature_vectors_cleaned[sample(size_features_vector, size_features_vector), ] #shuffle
vector_sampled<-vector_sampled[-which(is.na(vector_sampled$port)),] # removing  NA values from port 

aux_vector_sampled<-vector_sampled %>% select(-id,-modelsize,-class,-subclass,-proto) # removing non-required features
clusters <- kmeans(aux_vector_sampled,ncluster,nstart = 1) #removing NAs
vector_sampled <- cbind(vector_sampled, clusterid = clusters$cluster) #Adding clusterid
    
split_size_training = size_features_vector / step_size
i=1
results<-c()
#vector_sampled

for (i in c(200,2000,4000,7000)){
  trainset<-vector_sampled[1:i,]
  testset<-vector_sampled[(i+1):nrow(vector_sampled),]
  new_rfFit <- train(subclass ~ sp+wp+wnp+snp+ds+dm+dl+ss+sm+sl+clusterid+proto, #clusterid+proto
                 data = trainset,
                 metric="ROC",
                 method = "rf",
                 trControl = ctrl_fast)
  #Testing predict
  predsrfprobs <- predict(new_rfFit,testset,type='prob')
  results<-rbind(results,cbind(id=testset$id,size=i,prediction=predsrfprobs$botnet))  
  
}

results


```

### Dataset features.
```{r}
myData_cleaned <- read.csv('/home/jguerra/datasets/ctu13.labeled.cleaned', stringsAsFactors = F, sep = '|')
myData_cleaned
myData_cleaned$port <- as.factor(myData_cleaned$port)
myData_cleaned$proto <- as.factor(myData_cleaned$proto)
g_data_cleaned <- ggplot(data = myData_cleaned)
colors <- c( "#f8766dff","#00bfc4ff")

#Botnet and Normal Distribution
g_data_cleaned + geom_bar(aes(class),fill = colors ) +
labs(title="Class Distribution", 
       caption="Source: CTU-13",
       x = "class",
       y="number of connections", 
       color=NULL) + 
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.text=element_text(size=12),
        legend.justification=c(1,1),legend.position=c(1,1),legend.title=element_blank()) + 
  scale_fill_manual("legend", values = c("botnet" = "#00bfc4ff", "normal" = "#f8766dff")) + 
  theme_bw()

g_data_cleaned + geom_bar(aes(label)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
g_data_cleaned + geom_bar(aes(label)) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + scale_y_log10() 
ggplot(myData_cleaned %>% filter(class == 'botnet')) + geom_bar(aes(label)) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + scale_y_log10()
ggplot(myData_cleaned %>% filter(class == 'normal')) + geom_bar(aes(label)) + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + scale_y_log10()

#Port and protocol
g_data_cleaned + geom_bar(aes(port)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
g_data_cleaned + geom_bar(aes(proto))
ggplot(myData_cleaned %>% filter(proto == 'tcp')) + geom_bar(aes(port)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(myData_cleaned %>% filter(proto == 'udp')) + geom_bar(aes(port)) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

### Presentation Graph
```{r}

colors <- c( "#f8766dff","#00bfc4ff")
g_data_cleaned + geom_bar(aes(class),fill = colors ) +
labs(title="Class Distribution", 
       caption="Source: CTU-13",
       x = "class",
       y="number of connections", 
       color=NULL) + 
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.text=element_text(size=12),
        legend.justification=c(1,1),legend.position=c(1,1),legend.title=element_blank()) + 
  scale_fill_manual("legend", values = c("botnet" = "#00bfc4ff", "normal" = "#f8766dff")) + 
  theme_bw()

g_bot <- ggplot(myData_cleaned %>% filter(class == 'botnet')) +
  geom_bar(aes(label),fill = "#f8766dff" ) +
  labs(title="Botnet Subclass Distribution", 
       caption="Source: CTU-13",
       x = "subclass",
       y="number of connections", 
       color=NULL) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) + 
  scale_y_log10()
  

g_normal <- ggplot(myData_cleaned %>% filter(class == 'normal')) + geom_bar(aes(label),fill = colors[2]) + theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(title="Normal Subclass Distribution", 
       caption="Source: CTU-13",
       x = "subclass",
       y="number of connections", 
       color=NULL) + 
  scale_y_log10()
g_bot
g_normal

botnet_13 <- myData_cleaned %>% filter(class == 'botnet') %>% group_by(label) %>% summarise(n=n()) %>% arrange(desc(n))
botnet_13

myData_cleaned %>% group_by(port) %>% summarise(n=n()) %>% arrange(desc(n))
nrow(myData_cleaned)

g_bot <- ggplot(botnet_13[1:12,], aes(y = n)) +
  geom_col(aes(x = label),fill = "#f8766dff" ) +
  labs(title="Botnet Subclass Distribution", 
       caption="Source: CTU-13",
       x = "subclass",
       y="# of connections", 
       color=NULL) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) + 
  scale_y_log10()
g_bot

port_bot <- myData_cleaned %>% filter(class == 'botnet') %>% group_by(port) %>% summarise(n_bot = n()) %>% arrange(desc(n_bot))
port_norm <- myData_cleaned %>% filter(class == 'normal') %>% group_by(port) %>% summarise(n_norm = n()) %>% arrange(desc(n_norm))

ggplot(port_bot[1:10,], aes(y = n_bot)) +
  geom_col(aes(x = port),fill = colors[1] ) +
  labs(title="Botnet Port Distribution", 
       caption="Source: CTU-13",
       x = "subclass",
       y="# of connections", 
       color=NULL) + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

port_merge <- merge(port_bot[1:5,], port_norm[1:5,], by = "port", all = T)
port_merge[is.na(port_merge)] <- 0
port_merge
names(port_merge) <- c("port","botnet","normal")
library(reshape2)
melt(port_merge)

ggplot(melt(port_merge))+
  geom_col(aes(x=port,y=value,fill=variable))+
  labs(title="Port Distribution", 
       caption="Source: CTU-13",
       x = "port",
       y="number of connections", 
       color=NULL) + 
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.text=element_text(size=12),
        legend.justification=c(1,1),legend.position=c(1,1),legend.title=element_blank()) + 
  scale_fill_manual("Class", values = c("botnet" = "#f8766dff", "normal" = "#00bfc4ff"))
  #theme(axis.text.x = element_text(angle = 45, hjust = 1))
```